{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python's Next Top Model\n",
    "By The Good, The Bad and the Ugly aka. The Three Musketeers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome back to the wonderful Python universe of Credible Threats. We will continue the exploration of movies, and we're sure that our data project notebook will look at this notebook and think, *you complete me*. You might want to ask, *Magic mirror on the wall, who's the fairest one of all*, and the answer will be this notebook. This notebook will try to estimate the IMDb ratings of movies. And as a bonus, we even have a live-updating figure, which will leave you thinking, *it's alive, it's alive*. \n",
    "\n",
    "We will calculate the utility of each movie, given genres, awards, duration and so forth, and we will try to calculate the IMDb ratings for each movie, based on this utility. Finally, we will minimize the distance between our estimated ratings and the actual IMDb ratings. Now, we're sure you're thinking, *show me the money*, so this is it. \n",
    "\n",
    "Our utility function is given by: \n",
    "$$ U_i = \\sum_{k=1}^{23}(\\alpha_k G_{ik}) + \\sum_{k=1920}^{2010} (\\beta_k D_{ik}) + \\gamma N_i + \\delta W_i + \\rho L_i $$. \n",
    "\n",
    "$$\\text{Where, } G_{ik} \\text{ is genre } k \\text{, } D_{ik} \\text{ is decade } k \\text{, } N_i \\text{ is nominations, } W_i \\text{ is number of wins and } L_i \\text{ is duration. } $$ \n",
    "\n",
    "I think we can agree, it is *beauty kills the beast*. \n",
    "Now, based on this utility function, we will estimate the ratings of each movies,\n",
    "$$ R_i^{model} = \\frac{\\exp(\\omega x_i')}{1 + \\exp(\\omega x_i')} $$ \n",
    "\n",
    "where, \n",
    "$$ x_i = \\big[G_1, G_2, ..., G_{23}, D_{1920}, D_{1930}, ..., D_{2010}, N_i, W_i, L_i \\big] $$\n",
    "$$ \\omega = \\big[\\alpha_1, \\alpha_2, ..., \\alpha_{23}, \\beta_{1920}, \\beta_{1930}, \\beta_{2010}, \\gamma, \\delta, \\rho_1 \\big] $$\n",
    "\n",
    "*Yippie-ki-yay, motherfucker*, it's that nice? \n",
    "\n",
    "We then use optimize methods to solve the following: \n",
    "$$ \\min_{\\omega} \\Big\\{ \\sum_{i=1}^{n} \\left( R_i^{model} - R_i^{data} \\right)^2 \\Big\\} $$\n",
    "\n",
    "$$ \\text{where, } R_i^{model} \\text{ are the ratings from the dataset.}$$\n",
    "\n",
    "\n",
    "Throughout our notebook, you might *feel the need - the need for speed*. But, *patience you must have, my young Padawan*, because optimizing takes time. \n",
    "\n",
    "*Of all the python notebooks in all the towns in all the world, you walk into ours*. How lucky you are, you'll soon see why. \n",
    "\n",
    "So, *say hello to my little friend*, Python's next top model.  \n",
    "Let's *get busy coding, or get busy dying*. \n",
    "\n",
    "![test](https://media.giphy.com/media/LpkBAUDg53FI8xLmg1/giphy.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import itertools\n",
    "from ipywidgets import Layout\n",
    "import math\n",
    "\n",
    "import time\n",
    "from scipy import linalg\n",
    "import scipy.optimize as optimize\n",
    "import sympy as sm\n",
    "from data_gen import gen_df \n",
    "from IPython.display import clear_output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for later use \n",
    "variables = ['Action','Adventure','Animation','Biography','Comedy','Crime','Documentary',\n",
    "            'Drama','Family','Fantasy','FilmNoir','History','Horror','Music','Musical',\n",
    "            'Mystery','Romance','SciFi','Short','Sport','Thriller','War','Western',\n",
    "            'decade_1920','decade_1930','decade_1940','decade_1950','decade_1960',\n",
    "            'decade_1970','decade_1980','decade_1990','decade_2000','decade_2010',\n",
    "            'nrOfNominations','nrOfWins','duration']\n",
    "\n",
    "vars_dec = ['Action','Adventure','Animation','Biography','Comedy','Crime','Documentary',\n",
    "        'Drama','Family','Fantasy','FilmNoir','History','Horror','Music','Musical',\n",
    "        'Mystery','Romance','SciFi','Short','Sport','Thriller','War','Western',\n",
    "        'nrOfNominations','nrOfWins','duration']\n",
    "\n",
    "decade_list = [1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010]\n",
    "\n",
    "\n",
    "# Function to calculate squared mean differences \n",
    "\n",
    "# OBS: TilfÃ¸j evt. andre datadrames and variables (kommentar til Jake)\n",
    "def sqr_diff_sum(df_X,pars):\n",
    "    \"\"\" Generates a float of the sum of squared differences between the ratings from the data and the model. \n",
    "\n",
    "    Args: \n",
    "        df_X (DataFrame): DataFrame containing the variable in x for all observations.\n",
    "        pars (List): List of parameters in omega\n",
    "\n",
    "    Returns: \n",
    "        A float.\n",
    "    \"\"\"\n",
    "    # Calculate the matrix product between omega and X\n",
    "    util = df_X@pars  \n",
    "    # Scale the product so is between 0 and 10. This is the R_model\n",
    "    df_Y['rat_model'] = 10*np.exp(util)/(1+np.exp(util)) \n",
    "    # Calculate the squared difference between R_data and R_model\n",
    "    df_Y['sqr_diff'] = (df_Y['rat_model']-df_Y['rat_data'])**2 \n",
    "\n",
    "    return df_Y['sqr_diff'].sum() # Returns the sum of the squared differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_s(keep_top=None, decade=None):\n",
    "    \"\"\" Prepares data for optimization by creating dummmy-variables for decades, dropping movies with less than 5000 ratings,\n",
    "        dropping some variables that we don't wish to use in the model, and splitting the dataset, so we have a data set\n",
    "        consisting only of the variables used in the model.\n",
    "        \n",
    "    Args:\n",
    "        keep_top (optional, type: int): When a number (n) is put in this option, only the top n movies a kept in the dataset. This is used to remove movies for a better fit of the model\n",
    "\n",
    "    Returns:\n",
    "        df_X (type: Pandas dataframe): A dataframe consisting only of the varaibles that are used to calculate the rating.\n",
    "        df_Y (type: Pandas dataframe): A dataframe consisting of the true ratings from the dataset and an index-variable, used for merging with original dataset, later in the process.\n",
    "\n",
    "    Notice:\n",
    "        The function includes global for 'df', which means that the dataframe 'df' generated, can be called outside the function. This is used so that we won't have to filter the original dataframe everytime we use it.\n",
    "    \"\"\"\n",
    "    global df\n",
    "\n",
    "    # Calls the file 'imdb.csv' which is located in the repository, and contains the dataset used\n",
    "    filename = 'imdb.csv'\n",
    "\n",
    "    # A function generated earlier, which cleans the dataset [Should we include this, and do some of the filtering below in that funciton?]\n",
    "    df = gen_df(filename)\n",
    "\n",
    "    # Filters out movies with less than 5000 ratings and drops some genres\n",
    "    df = df.loc[(df['ratingCount']>=5000)]\n",
    "    df = df.drop(columns=['Adult','GameShow','News','RealityTV','TalkShow'])\n",
    "            \n",
    "    # Keeps only top n movies, if this is specified when calling the function\n",
    "    if keep_top != None:\n",
    "        df = df.sort_values('imdbRating', ascending=False)\n",
    "        df = df.iloc[:keep_top]\n",
    "    \n",
    "    if decade == None:\n",
    "        # Decade dummies\n",
    "        for i in decade_list:\n",
    "            df[f'decade_{i}'] = 0\n",
    "            df.loc[(df['decade'] == f'{i}s'),f'decade_{i}'] = 1\n",
    "        \n",
    "        # Splits the dataset into two datasets\n",
    "        df_X = df.copy()\n",
    "        df_Y = pd.DataFrame(df[['imdbRating', 'index']].copy())\n",
    "        df_Y = df_Y.rename(columns = {'imdbRating':'rat_data'})\n",
    "\n",
    "        # Rearrange and keep given columns \n",
    "        df_X = df_X.reindex(['Action','Adventure','Animation','Biography','Comedy','Crime','Documentary',\n",
    "                              'Drama','Family','Fantasy','FilmNoir','History','Horror','Music','Musical',\n",
    "                              'Mystery','Romance','SciFi','Short','Sport','Thriller','War','Western',\n",
    "                              'decade_1920','decade_1930','decade_1940','decade_1950','decade_1960',\n",
    "                              'decade_1970','decade_1980','decade_1990','decade_2000','decade_2010',\n",
    "                              'nrOfNominations','nrOfWins','duration'], axis=1)\n",
    "            \n",
    "    \n",
    "    if decade != None:\n",
    "        # Keeps movies from the specified decade\n",
    "        df = df.loc[df['decade'] == f'{decade}s'] \n",
    "\n",
    "        # Splits the dataset into two datasets\n",
    "        df_X = df.copy()\n",
    "        df_Y = pd.DataFrame(df[['imdbRating', 'index']].copy())\n",
    "        df_Y = df_Y.rename(columns = {'imdbRating':'rat_data'})\n",
    "\n",
    "        # Rearrange columns and keep the specified variables \n",
    "        df_X = df_X.reindex(['Action','Adventure','Animation','Biography','Comedy','Crime','Documentary',\n",
    "                                  'Drama','Family','Fantasy','FilmNoir','History','Horror','Music','Musical',\n",
    "                                  'Mystery','Romance','SciFi','Short','Sport','Thriller','War','Western',\n",
    "                                  'nrOfNominations','nrOfWins','duration'], axis=1)\n",
    "\n",
    "\n",
    "    return df_X, df_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "We analyze preferences for movies by minimizing the sum of the squared differences from our model prediction and the true rating, i.e.:\n",
    "$$ \n",
    "\\min_{\\omega} \\Big\\{ \\sum_{i=1}^{n} \\left( R_i^{model} - R_i^{data} \\right)^2 \\Big\\} \n",
    "$$ \n",
    "By doing so, we'll find parameters that best describe movie preferences given our model. As we will discuss later, our model is not necessarily the best model to describe preferences, which might lead to these preferences not being completely true. <br>\n",
    "If the model would predict all movie ratings correctly the parameters would perfectly describe movie preferences. For example if the parameter for action-movies were negative, the prediction would be precise, if action-movies generally had a negative impact on ratings. Of course people have much different preferences, and an interesting analysis would be, to predict preferences for different people, and by this look at a distribution of these parameters. This is not included in this project, though. <br>\n",
    "To shorten the length of the optimizing process, and to sort out movies that makes it harder for the model to predict preferences, the optimization can be based on the top n movies, based on IMDb rating. When all movies are included in the optimizer the lowest ranking movies will have ratings around 2. Our rating predictor will in this case not rank any movies under 5. Thereby it is clear that the predictor model is not able to predict movies with very low rating. But it is able to predict movies with higher ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(keep_top=None, live_graph=True):\n",
    "    \"\"\" Creates and optimizes the function which calculates rating based on variables in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        keep_top (optional, type: int): When a number (n) is put in this option, only the top n movies a kept in the dataset. This is used to sort out movies for a better fit of the model\n",
    "        live_graph(optional, type: boolean): Produces a live graph of the optimization proces, plotting the function values against the iterations. Makes the optimizer slower, but is a good visualization of the process.\n",
    "                                             \n",
    "    Returns:\n",
    "        result (type: scipy optimizer object): An object containing results from the optimizer among other information such as status etc.\n",
    "        timer (type: int): Time of running optimizer in seconds.\n",
    "                                               \n",
    "    Notice:\n",
    "        Uses the package scipy.optimize.minimize which optimizes functions based on a given method. Here 'Nelder-Mead' is used.\n",
    "        This function defines a set of functions used in the optimizer which are not documented by docstring but comments in code.\n",
    "    \"\"\"\n",
    "    # \"Initializes\" a timer for printing time of optimization\n",
    "    start = time.time()\n",
    "    \n",
    "    # Set of globals, so variables can be called inside the functions defined in this function\n",
    "    global fs\n",
    "    global evals\n",
    "    global x0\n",
    "    global df\n",
    "    global df_Y\n",
    "        \n",
    "    # Plots a live graph of optimization process, if chosen.\n",
    "    if live_graph:\n",
    "        # The live plot is created by taking the function value for each iteration and saving in a list\n",
    "        def live_plot(evals, fs, ymax=10000, figsize=(7,5)):\n",
    "            # Clears plot every time a new plot is created\n",
    "            clear_output(wait=True)\n",
    "            plt.figure(figsize=figsize)\n",
    "\n",
    "            # Plots values and sets title, grid, labels, etc.\n",
    "            plt.plot(evals, fs)\n",
    "            plt.title('Figure 1: Optimizing path')\n",
    "            plt.grid(True)\n",
    "            plt.xlabel('Iterations')\n",
    "            plt.ylabel('Function value')\n",
    "            plt.xlim(0,17500)\n",
    "            plt.ylim(0,ymax)\n",
    "\n",
    "            plt.show();\n",
    "\n",
    "    # Function to be called by optimizer each iteration. This returns function values for each iteration and plots live graph\n",
    "    def collect(x):\n",
    "        # Set of globals to be called in live graph-function\n",
    "        global fs\n",
    "        global evals\n",
    "        global x0\n",
    "        global fig\n",
    "        global ax\n",
    "        global ymax\n",
    "        global x_1 \n",
    "        global x_2 \n",
    "        global x_3 \n",
    "        global x_4\n",
    "        global x_5 \n",
    "        global x_6 \n",
    "        global x_7 \n",
    "        global x_8\n",
    "        global x_9 \n",
    "        global x_10\n",
    "        global x_11 \n",
    "        global x_12 \n",
    "        global x_13 \n",
    "        global x_14\n",
    "        global x_15 \n",
    "        global x_16 \n",
    "        global x_17 \n",
    "        global x_18\n",
    "        global x_19 \n",
    "        global x_20\n",
    "        global x_21 \n",
    "        global x_22 \n",
    "        global x_23 \n",
    "        global x_24\n",
    "        global x_25 \n",
    "        global x_26 \n",
    "        global x_27 \n",
    "        global x_28\n",
    "        global x_29 \n",
    "        global x_30\n",
    "        global x_31 \n",
    "        global x_32 \n",
    "        global x_33 \n",
    "        global x_34\n",
    "        global x_35 \n",
    "        global x_36 \n",
    "\n",
    "\n",
    "        # Calculates function value for initial guess, for first iteration\n",
    "        if evals == 0:\n",
    "            fs = []\n",
    "            fs.append(obj_fun(x0))\n",
    "            # Generates vector of parameter estimates \n",
    "            x_1 = [x0[0]] \n",
    "            x_2 = [x0[1]]\n",
    "            x_3 = [x0[2]] \n",
    "            x_4 = [x0[3]]\n",
    "            x_5 = [x0[4]] \n",
    "            x_6 = [x0[5]]\n",
    "            x_7 = [x0[6]] \n",
    "            x_8 = [x0[7]]\n",
    "            x_9 = [x0[8]] \n",
    "            x_10 = [x0[9]]\n",
    "            x_11 = [x0[10]] \n",
    "            x_12 = [x0[11]]\n",
    "            x_13 = [x0[12]] \n",
    "            x_14 = [x0[13]]\n",
    "            x_15 = [x0[14]] \n",
    "            x_16 = [x0[15]]\n",
    "            x_17 = [x0[16]] \n",
    "            x_18 = [x0[17]]\n",
    "            x_19 = [x0[18]] \n",
    "            x_20 = [x0[19]]\n",
    "            x_21 = [x0[20]] \n",
    "            x_22 = [x0[21]]\n",
    "            x_23 = [x0[22]] \n",
    "            x_24 = [x0[23]]\n",
    "            x_25 = [x0[24]] \n",
    "            x_26 = [x0[25]]\n",
    "            x_27 = [x0[26]] \n",
    "            x_28 = [x0[27]]\n",
    "            x_29 = [x0[28]] \n",
    "            x_30 = [x0[29]]\n",
    "            x_31 = [x0[30]] \n",
    "            x_32 = [x0[31]]\n",
    "            x_33 = [x0[32]] \n",
    "            x_34 = [x0[33]]\n",
    "            x_35 = [x0[34]] \n",
    "            x_36 = [x0[35]]\n",
    "\n",
    "        # Calculates function values for current parameter values\n",
    "        if evals != 0:\n",
    "            fs.append(obj_fun(x))\n",
    "        \n",
    "        # Plots live graph if chosen\n",
    "        if live_graph:\n",
    "            # Calculates max y-value for axis for first iteration\n",
    "            if evals == 1:\n",
    "                ymax = math.ceil(obj_fun(x)/2000)*2000\n",
    "\n",
    "            # Updates plot every 100th iteration for the first 1000 iterations\n",
    "            if evals < 1000:\n",
    "                if evals > 0 and evals%100 == 0:\n",
    "                    live_plot(range(evals+1), fs, ymax)\n",
    "            # Updates plot every 500th iteration for the rest of the process\n",
    "            if evals >=1000:\n",
    "                if evals%500 == 0:\n",
    "                    live_plot(range(evals+1), fs, ymax)\n",
    "        \n",
    "        # Appends esimtates to x_vectors \n",
    "        x_1.append(x[0])\n",
    "        x_2.append(x[1])\n",
    "        x_3.append(x[2])\n",
    "        x_4.append(x[3])\n",
    "        x_5.append(x[4])\n",
    "        x_6.append(x[5])\n",
    "        x_7.append(x[6])\n",
    "        x_8.append(x[7])\n",
    "        x_9.append(x[8])\n",
    "        x_10.append(x[9])\n",
    "        x_11.append(x[10])\n",
    "        x_12.append(x[11])\n",
    "        x_13.append(x[12])\n",
    "        x_14.append(x[13])\n",
    "        x_15.append(x[14])\n",
    "        x_16.append(x[15])\n",
    "        x_17.append(x[16])\n",
    "        x_18.append(x[17])\n",
    "        x_19.append(x[18])\n",
    "        x_20.append(x[19])\n",
    "        x_21.append(x[20])\n",
    "        x_22.append(x[21])\n",
    "        x_23.append(x[22])\n",
    "        x_24.append(x[23])\n",
    "        x_25.append(x[24])\n",
    "        x_26.append(x[25])\n",
    "        x_27.append(x[26])\n",
    "        x_28.append(x[27])\n",
    "        x_29.append(x[28])\n",
    "        x_30.append(x[29])\n",
    "        x_31.append(x[30])\n",
    "        x_32.append(x[31])\n",
    "        x_33.append(x[32])\n",
    "        x_34.append(x[33])\n",
    "        x_35.append(x[34])\n",
    "        x_36.append(x[35])\n",
    "        \n",
    "        # Adds one to the number of iterations each iteration\n",
    "        evals += 1\n",
    "    \n",
    "        \n",
    "    # Define datasets to be used using function defined earlier\n",
    "    df_X, df_Y = df_s(keep_top=keep_top, decade=None)\n",
    "    \n",
    "    # Intiial guess\n",
    "    x0 = np.zeros(len(variables))\n",
    "    \n",
    "    # Start iteration number\n",
    "    evals = 0\n",
    "    \n",
    "    # Defines function to be minimized\n",
    "    obj_fun = lambda x: sqr_diff_sum(df_X,x)\n",
    "    \n",
    "    # Run optimizer\n",
    "    result = optimize.minimize(obj_fun,x0,\n",
    "                               method=\"Nelder-Mead\",\n",
    "                               options={\"disp\":True, \"maxiter\":50000}, # display the results\n",
    "                               callback=collect\n",
    "                               ) \n",
    "    \n",
    "    # End timer\n",
    "    end = time.time()-start\n",
    "    \n",
    "    # Returns\n",
    "    return result, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 3735.382286\n",
      "         Iterations: 16566\n",
      "         Function evaluations: 19203\n",
      "         Time: 71.1281 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run optimizer function and print results and time\n",
    "result, timer = optimizer()\n",
    "print(f'{\" \":9s}Time: {timer:.4f} seconds')\n",
    "\n",
    "# Keep copy of df and df_Y for later purpose\n",
    "df_Y_all = df_Y.copy()\n",
    "df_all = df.copy()\n",
    "      \n",
    "\n",
    "results = dict()\n",
    "\n",
    "for j,i in enumerate(variables):\n",
    "    results[i] = result.x[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action : -0.02\n",
      "Adventure : -0.03\n",
      "Animation : 0.17\n",
      "Biography : -0.17\n",
      "Comedy : -0.02\n",
      "Crime : -0.03\n",
      "Documentary : 0.11\n",
      "Drama : 0.13\n",
      "Family : -0.06\n",
      "Fantasy : -0.33\n",
      "FilmNoir : 0.02\n",
      "History : -0.08\n",
      "Horror : -0.02\n",
      "Music : -0.03\n",
      "Musical : -0.08\n",
      "Mystery : -0.09\n",
      "Romance : -0.04\n",
      "SciFi : -0.10\n",
      "Short : 0.12\n",
      "Sport : -0.06\n",
      "Thriller : -0.06\n",
      "War : 0.19\n",
      "Western : 0.03\n",
      "decade_1920 : -0.04\n",
      "decade_1930 : 0.12\n",
      "decade_1940 : 0.18\n",
      "decade_1950 : -0.03\n",
      "decade_1960 : 0.31\n",
      "decade_1970 : 0.10\n",
      "decade_1980 : 0.01\n",
      "decade_1990 : -0.22\n",
      "decade_2000 : -0.20\n",
      "decade_2010 : -0.21\n",
      "nrOfNominations : 0.00\n",
      "nrOfWins : 0.02\n",
      "duration : 0.45\n"
     ]
    }
   ],
   "source": [
    "# List of Parameter Estimates \n",
    "\n",
    "# Constructs dictionary with parameters \n",
    "preben = dict()\n",
    "for j,i in enumerate(variables):\n",
    "    preben[i] = f'{result.x[j]:.2f}'\n",
    "\n",
    "\n",
    "# Prints list of parameterestimes \n",
    "for i in preben: \n",
    "    print (i, \":\", preben[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2976001507654f93a8a67600e0e88b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Variable', options=('Action', 'Adventure', 'Animation', 'Biographyâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Convergence of Parameter Estimates \n",
    "\n",
    "# Constructing dataframe which contains all parameter vectors as variables\n",
    "par_dict = {\"Action\": x_1,\n",
    "             \"Adventure\": x_2,\n",
    "             \"Animation\": x_3,\n",
    "             \"Biography\": x_4,\n",
    "             \"Comedy\": x_5,\n",
    "             \"Crime\": x_6,\n",
    "             \"Documentary\": x_7,\n",
    "             \"Drama\": x_8, \n",
    "             \"Family\": x_9,\n",
    "             \"Fantasy\": x_10,\n",
    "             \"Film Noir\": x_11,\n",
    "             \"History\": x_12,\n",
    "             \"Horror\": x_13,\n",
    "             \"Music\": x_14,\n",
    "             \"Musical\": x_15,\n",
    "             \"Mystery\": x_16,\n",
    "             \"Romance\": x_17,\n",
    "             \"SciFi\": x_18, \n",
    "             \"Short\": x_19,\n",
    "             \"Sport\": x_20,\n",
    "             \"Thriller\": x_21,\n",
    "             \"War\": x_22,\n",
    "             \"Western\": x_23,\n",
    "             \"1920's\": x_24,\n",
    "             \"1930's\": x_25,\n",
    "             \"1940's\": x_26,\n",
    "             \"1950's\": x_27,\n",
    "             \"1960's\": x_28,\n",
    "             \"1970's\": x_29,\n",
    "             \"1980's\": x_30,\n",
    "             \"1990's\": x_31,\n",
    "             \"2000's\": x_32,\n",
    "             \"2010's\": x_33,\n",
    "             \"Nr. of Nominations\": x_34, \n",
    "             \"Nr. of Wins\": x_35, \n",
    "             \"Duration\": x_36\n",
    "            }\n",
    "\n",
    "df_par = pd.DataFrame(par_dict)\n",
    "\n",
    "\n",
    "##  Interactive graph of parametervalues for each iteration in optimizer \n",
    "# Chose which parameter to show \n",
    "\n",
    "# Interactive graph of parameter estimates\n",
    "def graph(par):\n",
    "    \"\"\"\n",
    "    Constructs a graph which shows the progress in parameter estimates foreach iteration in\n",
    "    the optimizing process. \n",
    "    \n",
    "    Args: \n",
    "        par (str): Variable name, for which the graphs shows the parameter estimates. \n",
    "                \n",
    "    Returns: \n",
    "        Graph of progress in parameter estimates. \n",
    "        \n",
    "    Notice: \n",
    "        The function is meant to be called within the graph_int function. \n",
    "        The graph_int function turns this graph into an interactive function, where the \n",
    "        user can choose between variables. \n",
    "        Thus, the graph is not meant to be run on its own. \n",
    "    \"\"\"\n",
    "    # Generating figure \n",
    "    plt.plot(df_par[par])\n",
    "    \n",
    "    # Grid and axes \n",
    "    plt.grid(True)\n",
    "    plt.axhline(df_par[par].iloc[-1], linestyle=\"dashed\", color=\"orange\", label=\"Optimum\")\n",
    "    \n",
    "    # Labels and Titles \n",
    "    plt.title(\"Figure 2: Progress in Parameter Estimation\")\n",
    "    plt.ylabel(\"Parameter Estimate\")\n",
    "    plt.xlabel(\"Nr. of Iterations\")\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "# Interactive part: Choose between parameters \n",
    "def graph_int(): \n",
    "    \"\"\"\n",
    "    Constructs interactive graph from the graph function. \n",
    "    \"\"\"\n",
    "    widgets.interact(graph, \n",
    "                     par = widgets.Dropdown( \n",
    "                     description=\"Variable\", \n",
    "                     options=df_par.columns.values, \n",
    "                     value=\"Action\"));\n",
    "graph_int()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above figure, we notice that most parameter estimates are very volatile in the first 10,000-15,000 iterations, following which they converge towards the optimum value. \n",
    "\n",
    "However, this does not appear to be the case for the variables, Nr. of nominations and Nr. of awards, which get quite close to the optimum value at around the 7500th iteration. \n",
    "Additionally, we notice that the variable Duration appears to have the largest effect on ratings, which the optimzer seems to realize after approximately 2500 iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 213.265323\n",
      "         Iterations: 17235\n",
      "         Function evaluations: 19895\n",
      "         Time: 43.4493 seconds\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 582.831479\n",
      "         Iterations: 16138\n",
      "         Function evaluations: 18644\n",
      "         Time: 42.0408 seconds\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 895.336144\n",
      "         Iterations: 19477\n",
      "         Function evaluations: 22457\n",
      "         Time: 55.4331 seconds\n"
     ]
    }
   ],
   "source": [
    "## This piece of code solve the model for three different sample size\n",
    "\n",
    "#### OBS: The code will take a couple of minutes to run because the model is solved three times!! ####\n",
    "\n",
    "# List to store result for the optimization with the different sample sizes\n",
    "results_list = [result.x]\n",
    "\n",
    "# This loop solve the model for the top 500, 1000, and 2000 movies\n",
    "for i in [500, 1000, 2000]:\n",
    "    res_temp, timer_temp = optimizer(keep_top=i, live_graph=False)\n",
    "    temp = res_temp.x\n",
    "    print(f'{\" \":9s}Time: {timer_temp:.4f} seconds')\n",
    "    results_list.append(temp) # Store the results in the 'results_list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99519cf5ed4942c8ad0ffc6ba1202dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Nr. of movies', options=('All', 500, 1000, 2000), value='All'), Ouâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The code creates an interactive plot of the estimated parameters for all variables. \n",
    "## In the interactive part you can choose between estimates when the model is solved \n",
    "## for all movies or just top top 500, 1000, or 2000 rated movies. \n",
    "\n",
    "def fig_2(val):\n",
    "    \"\"\" Generates a figure which plots estimated parameters for all variables.\n",
    "\n",
    "    Args: \n",
    "        val (string or int): Should be one of the elements in the options-list\n",
    "\n",
    "    Returns: \n",
    "        One interactive plot.  \n",
    "\n",
    "    Notice: \n",
    "        The function is generated so that it can be called using widgets.interact. \n",
    "        Thus, it is not intended to be used on its own. \n",
    "    \"\"\"    \n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    ax1 = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    # Plots the estimated parameters for the chosen sample of movies\n",
    "    ax1.bar(variables, results_list[options.index(val)], label=f'Estimates with {options[options.index(val)]} movies')\n",
    "    \n",
    "    # Scatter plot with the estimated paramters for the entire sample \n",
    "    ax1.scatter(variables, results_list[0], marker='D', s=15, zorder=2, label='Estimates with all movies')\n",
    "    \n",
    "    # Legends and labels \n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax1.set_ylabel('Parameter estimates')\n",
    "    ax1.set_title(f'Figure 3: Parameter estimates for {options[options.index(val)]} movies')\n",
    "    ax1.set_ylim([-0.7,0.7])\n",
    "    ax1.axhline(y=0,color='black',linewidth=1)\n",
    "    for tick in ax1.get_xticklabels():\n",
    "        tick.set_rotation(90)\n",
    "        \n",
    "options = ['All', 500, 1000, 2000] # Option list\n",
    "\n",
    "# Making the figure interactive so the estimates are shown for the chosen sample size \n",
    "widgets.interact(fig_2,\n",
    "    val = widgets.Dropdown(description='Nr. of movies', value='All', options=options, \n",
    "                ),\n",
    ");   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction precision\n",
    "Ideally our model would predict movie ratings perfectly, and thereby our parameters would perfectly describe the general preferences for movies. Whether this is possible, even with an advanced model, is not sure. People have different preferences, and two movies that would seem identical in our dataset, based on genres, duration, time of release, etc. could have very different ratings. Therefore som devitaion in our prediction from the true ratings are expected. <br>\n",
    "The left graphs above plot the mean of deviations based on genres, duration, decades, and true ratings. The right graphs plot the number of movies in the dataset based on the same groups. From these graphs we see a clear correlation between precision and number of movies in the dataset. The more movies of a given genre, duration, etc. the more precise the prediction of movie-ratings in these groups. Take drama-movies as an example. The mean of the deviation is close to zero, and movies of this genre is also quite overrepresentated in the dataset. The complete opposite case is short-movies. But we also see that sci-fi-movies are quite well predicted, even though there aren't relatively many of these movies in the dataset. The same is seen in other different genres. <br>\n",
    "This general image is seen when we group movies on decades, duration, and true rating as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c303bda6be47d6bf3c792baae6681f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Group', options=('Genres', 'Decades', 'Duration', 'True rating'), â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def merge_df(df_org):\n",
    "    \"\"\" Merges the original dataset with the optimal solution from the optimizer, i.e. the last dataset of calculated raitngs.\n",
    "    \n",
    "    Args:\n",
    "        df_org (type: Pandas dataframe): The orignal dataset of movies, containing true ratings.\n",
    "        \n",
    "    Returns:\n",
    "        df_merge (type: Pandas dataframe): Original dataset combined with calculated ratings from optimal parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Merges original dataset with optimal ratings based on model\n",
    "    df_merge = df_org.merge(df_Y_all, how='right', left_on='index', right_on='index')\n",
    "\n",
    "    # Calculates deviations both in normal and absolute form \n",
    "    df_merge['abs_diff'] = abs(df_merge['rat_model']-df_merge['rat_data'])\n",
    "    df_merge['diff'] = df_merge['rat_model']-df_merge['rat_data']\n",
    "    \n",
    "    return df_merge\n",
    "\n",
    "\n",
    "def _mean_genre(df,group, diff):  \n",
    "    \"\"\" Calculates the mean of deviations from true ratings and ratings based on optimal parameters from optimizer.\n",
    "    \n",
    "    Args:\n",
    "        df (type: Pandas dataframe): Dataframe consisting information on groups and deivations\n",
    "        group (type: string): Defines which group mean of deviations are presented for. Chosen by fixed list in widget.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "        \n",
    "    Notice:\n",
    "        Only to be run through widget.interact()\n",
    "    \"\"\"\n",
    "    # List of values used for each group\n",
    "    genre_list = ['Action','Adventure','Animation','Biography','Comedy','Crime','Documentary',\n",
    "                    'Drama','Family','Fantasy','FilmNoir','History','Horror','Music','Musical',\n",
    "                    'Mystery','Romance','SciFi','Short','Sport','Thriller','War','Western']\n",
    "    \n",
    "    decade_list = ['1920s', '1930s', '1940s', '1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s']\n",
    "    \n",
    "    dur_list = [0, .5, 1, 1.5, 2, 2.5, 3, 3.5]\n",
    "    \n",
    "    rat_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    \n",
    "    mean_dict = dict()\n",
    "    count_dict = dict()\n",
    "    \n",
    "    if diff == 'Absolute':\n",
    "        diff_col = 'abs_diff'\n",
    "    else:\n",
    "        diff_col = 'diff'\n",
    "    \n",
    "    # Creates dictionaries based on chosen group\n",
    "    if group == 'Genres':\n",
    "        for i in genre_list:\n",
    "            I = df[i] == 1\n",
    "            mean_dict[i] = df.loc[I][diff_col].mean()\n",
    "            count_dict[i] = df.loc[I]['index'].count()    \n",
    "\n",
    "    if group == 'Decades':\n",
    "        for i in decade_list:\n",
    "            I = df['decade'] == i\n",
    "            mean_dict[i] = df.loc[I][diff_col].mean()\n",
    "            count_dict[i] = df.loc[I]['index'].count()\n",
    "\n",
    "    if group == 'Duration':\n",
    "        for j,i in enumerate(dur_list):\n",
    "            if j != len(dur_list)-1:\n",
    "                # Uses values from dict, to find movies between to items in the lists.\n",
    "                I = ((df['duration'] >= dur_list[j]) & (df['duration'] < dur_list[j+1]))\n",
    "                mean_dict[f'{dur_list[j]:2.1f} - {dur_list[j+1]:2.1f}'] = df.loc[I][diff_col].mean()\n",
    "                count_dict[f'{dur_list[j]:2.1f} - {dur_list[j+1]:2.1f}'] = df.loc[I]['index'].count()\n",
    "            else:\n",
    "                I = df['duration'] >= dur_list[j]\n",
    "                mean_dict[f'{dur_list[j]:2.1f} {\"+\":5s}'] = df.loc[I][diff_col].mean()\n",
    "                count_dict[f'{dur_list[j]:2.1f} {\"+\":5s}'] = df.loc[I]['index'].count()\n",
    "\n",
    "    if group == 'True rating':\n",
    "        for j,i in enumerate(rat_list):\n",
    "            if j != len(rat_list)-1:\n",
    "                # Uses values from dict, to find movies between to items in the lists.\n",
    "                I = ((df['rat_data'] >= rat_list[j]) & (df['rat_data'] < rat_list[j+1]))\n",
    "                mean_dict[f'{rat_list[j]:4.1f} - {rat_list[j+1]:3.1f}'] = df.loc[I][diff_col].mean()\n",
    "                count_dict[f'{rat_list[j]:4.1f} - {rat_list[j+1]:3.1f}'] = df.loc[I]['index'].count()\n",
    "            else:\n",
    "                pass\n",
    "                           \n",
    "    # Creates figure to hold two subplots \n",
    "    fig1, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,sharey=True,figsize=(12,5)\n",
    "    plt.title(\"Figure 4\")\n",
    "                           \n",
    "    # Plots means of deviations\n",
    "    ax1.barh(*zip(*mean_dict.items()))\n",
    "    ax1.set_ylabel(group)\n",
    "    ax1.set_xlabel('Model deviation')\n",
    "    ax1.grid(axis='x')\n",
    "                           \n",
    "    # Plots count of movies\n",
    "    ax2.barh(*zip(*count_dict.items()))\n",
    "    ax2.set_xlabel('Number of observations')\n",
    "    ax2.grid(axis='x')\n",
    "    \n",
    "    \n",
    "# Calls merge-function\n",
    "df_merge = merge_df(df_all) \n",
    "\n",
    "# Runs interactive figure \n",
    "mean_genre = widgets.interact(_mean_genre, \n",
    "                             df = widgets.fixed(df_merge),\n",
    "                             group = widgets.Dropdown(\n",
    "                                 options = ['Genres','Decades','Duration','True rating'],\n",
    "                                 description = 'Group',\n",
    "                                 value = 'Genres'),\n",
    "                             diff = widgets.RadioButtons(\n",
    "                                 options = ['Average', 'Absolute'],\n",
    "                                 description = 'Difference',\n",
    "                                 value = 'Average'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 2.582968\n",
      "         Iterations: 11001\n",
      "         Function evaluations: 13220\n",
      "         Time: 17.6457\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 10.430401\n",
      "         Iterations: 7505\n",
      "         Function evaluations: 9054\n",
      "         Time: 11.7576\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 16.979539\n",
      "         Iterations: 10375\n",
      "         Function evaluations: 12513\n",
      "         Time: 16.9444\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 70.590249\n",
      "         Iterations: 11004\n",
      "         Function evaluations: 13214\n",
      "         Time: 19.9966\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 87.282326\n",
      "         Iterations: 13058\n",
      "         Function evaluations: 15676\n",
      "         Time: 20.4386\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 43.754272\n",
      "         Iterations: 8422\n",
      "         Function evaluations: 10092\n",
      "         Time: 13.2377\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 58.218609\n",
      "         Iterations: 8914\n",
      "         Function evaluations: 10702\n",
      "         Time: 14.8270\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 117.040773\n",
      "         Iterations: 9296\n",
      "         Function evaluations: 11201\n",
      "         Time: 15.1694\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 173.340486\n",
      "         Iterations: 7557\n",
      "         Function evaluations: 9128\n",
      "         Time: 12.6752\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 39.431208\n",
      "         Iterations: 7880\n",
      "         Function evaluations: 9542\n",
      "         Time: 13.4536\n"
     ]
    }
   ],
   "source": [
    "## The following code produces the parameter estimates where the sample is restricted to all the decades,\n",
    "## one at the time. The function return a list which contains a list of the estimates for every decade.\n",
    "\n",
    "#### OBS: The code will take about 3-4 minutes to run, since the model is estimated 10 times!! ####\n",
    "\n",
    "def optimizer_dec():\n",
    "    \"\"\" Generates a list containing 10 list with estimates of the model for every decade. \n",
    "    \n",
    "    Args: \n",
    "        No arguments are needed.\n",
    "        \n",
    "    Returns: \n",
    "        A list.\n",
    "        \n",
    "    Notice: \n",
    "        It will raise an error if the function are given an argument!\n",
    "    \"\"\"\n",
    "              \n",
    "    result = [] # Empty list to store the estimated parameters\n",
    "    \n",
    "    # Make a loop so the model is estimated for all ten decade\n",
    "    for decade in decade_list:      \n",
    "        df_X, df_Y = df_s(keep_top=None, decade=decade) # Call the function to generate the two dataframes\n",
    "        x0 = np.zeros(len(vars_dec)) # Starting values \n",
    "    \n",
    "        obj_fun = lambda x: sqr_diff_sum(df_X,x) # The objective function -> sum of squared differences\n",
    "        start = time.time()\n",
    "        # Use Scipy optimizer to solve the model\n",
    "        result_i = optimize.minimize(obj_fun,x0,\n",
    "                               method='Nelder-Mead',\n",
    "                               options={\"disp\":True, \"maxiter\":50000}, # display the results\n",
    "                               );\n",
    "        end_time = time.time()-start\n",
    "        print(f'{\" \":9s}Time: {end_time:.4f}')\n",
    "        # Add the result for each deacde to the result-list\n",
    "        result.append(list(result_i.x)) \n",
    "                      \n",
    "    return result # Returns the result-list\n",
    "\n",
    "# Call the optimize_dec function\n",
    "result_dec = optimizer_dec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d178cf9ec5284552a673807bdf011e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Variable', options=('Action', 'Adventure', 'Animation', 'Biographyâ¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The following code produces a figure with the estimated parameters for each deacde for a chosen variable \n",
    "\n",
    "result_dec_mod = [] # Empty list to storage \n",
    "\n",
    "# The loop changes the order of the result-list so the \n",
    "# estimates are ordered by the variables and subordered by decade \n",
    "# insted of being ordered by decade and subordered by variables \n",
    "for j,var in enumerate(vars_dec):\n",
    "    temp = []\n",
    "    for i,dec in enumerate(decade_list):\n",
    "        temp.append(result_dec[i][j])\n",
    "    \n",
    "    result_dec_mod.append(temp)    \n",
    "    \n",
    "# Defining a figure to plot the estimates \n",
    "def fig(var):\n",
    "    \"\"\" Generates a figure which plots estimated parameters for each decade for one variable \n",
    "\n",
    "    Args: \n",
    "        var (string): Should be one of the variables in the X-vector\n",
    "\n",
    "    Returns: \n",
    "        One interactive plot.  \n",
    "\n",
    "    Notice: \n",
    "        The function is generated so that it can be called using widgets.interact. \n",
    "        Thus, it is not intended to be used on its own. \n",
    "        \"\"\"\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax1 = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    \n",
    "    ax1.bar(decade_list, result_dec_mod[vars_dec.index(var)],width=6)\n",
    "    \n",
    "    # Setting labels, ticks etc. \n",
    "    ax1.set_ylabel('Parameter estimates')\n",
    "    ax1.set_title(f'Figure 5: Parameter estimates for {var} per decade')\n",
    "    ax1.set_xticks(decade_list)\n",
    "    ax1.axhline(y=0,color='black',linewidth=1)\n",
    "\n",
    "# Making the figure interactive so the estimates are shown for the chosen variable \n",
    "widgets.interact(fig,\n",
    "    var = widgets.Dropdown(description='Variable', value='Action', options=vars_dec, \n",
    "                ),\n",
    ");    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Based on the above analysis, we conclude that our model is not very precise at predicting IMDb ratings when we consider our full sample. That being said, as we limit our sample size, either by decade, or by number of movies, our model performs better. This, however, might be the result of a decreased sample size, and the model must fit fewer observations. As can be seen from the optimization with the 500, 1000 and 2000 top rated movies, our model is best at predicting the top 500 movies. Similarly, our model preforms better in the first 3, or the very last decade, which are the decades that contain the lowest number of movies. Additionally, we know from the swarm plot in our data project, that movies in the early decades have a lower variation in ratings which, just as when we restrict our sample to top rated movies, decreases the number of possible ratings to estimates, which simplifies the task for our model. \n",
    "\n",
    "As can be seem from figure 3, duration appears to increase ratings by quite a lot, while Nr. of nominations and Nr. of wins doesn't appear to play a role, at least in the later decades. Meanwhile, the effect of different genres and decades are quite different. We see that genres like Action and Horror have very little effect on ratings, while the Fantasy movies appear to be very popular. \n",
    "\n",
    "As can be seen from figure 4, our model is quite good at predicting rating for SciFi, Drama and Comedy, while it misses on genres like shorts and Documentaries. The latter might be explained by the fact, that these genres contain quite few observations, and these observations might have quite different ratings. \n",
    "\n",
    "The model might be improved by including additional information such as budget, box office, director, actors, etc., which is information we do not have access to. Therefore, we conclude, that *much to learn, we still have*. \n",
    "\n",
    "However, we hope you enjoyed our movie model project. \n",
    "\n",
    "![The end](https://media.giphy.com/media/lD76yTC5zxZPG/giphy.gif)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
