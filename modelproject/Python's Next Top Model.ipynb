{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python's Next Top Model\n",
    "By The Good, The Bad and the Ugly aka. The Three Musketeers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome back to the wonderful Python universe of Credible Threats. We will continue the exploration of movies, and we're sure that our data project notebook will look at this notebook and think, *you complete me*. You might want to ask, *Magic mirror on the wall, who's the fairest one of all*, and the answer will be this notebook. This notebook will try to estimate the IMDb ratings of movies. And as a bonus, we even have a live-updating figure, which will leave you thinking, *it's alive, it's alive*. \n",
    "\n",
    "We will calculate the utility of each movie, given genres, awards, duration and so forth, and we will try to calculate the IMDb ratings for each movie, based on this utility. Finally, we will minimize the distance between our estimated ratings and the actual IMDb ratings. Now, we're sure you're thinking, *show me the money*, so this is it. \n",
    "\n",
    "Our utility function is given by: \n",
    "$$ U_i = \\sum_{k=1}^{23}(\\alpha_k G_{ik}) + \\sum_{k=1920}^{2010} (\\beta_k D_{ik}) + \\gamma N_i + \\delta W_i + \\rho L_i $$. \n",
    "\n",
    "$$\\text{Where, } G_{ik} \\text{ is genre } k \\text{, } D_{ik} \\text{ is decade } k \\text{, } N_i \\text{ is nominations, } W_i \\text{ is number of wins and } L_i \\text{ is duration. } $$ \n",
    "\n",
    "I think we can agree, it is *beauty kills the beast*. \n",
    "Now, based on this utility function, we will estimate the ratings of each movies,\n",
    "$$ R_i^{model} = \\frac{\\exp(\\omega x_i')}{1 + \\exp(\\omega x_i')} $$ \n",
    "\n",
    "where, \n",
    "$$ x_i = \\big[G_1, G_2, ..., G_{23}, D_{1920}, D_{1930}, ..., D_{2010}, N_i, W_i, L_i \\big] $$\n",
    "$$ \\omega = \\big[\\alpha_1, \\alpha_2, ..., \\alpha_{23}, \\beta_{1920}, \\beta_{1930}, \\beta_{2010}, \\gamma, \\delta, \\rho_1 \\big] $$\n",
    "\n",
    "*Yippie-ki-yay, motherfucker*, it's that nice? \n",
    "\n",
    "We then use optimize methods to solve the following: \n",
    "$$ \\min_{\\omega} \\Big\\{ \\sum_{i=1}^{n} \\left( R_i^{model} - R_i^{data} \\right)^2 \\Big\\} $$\n",
    "\n",
    "where, \n",
    "$$ R_i^{model}$$ are the ratings from the dataset. \n",
    "\n",
    "\n",
    "Throughout our notebook, you might *feel the need - the need for speed*. But, *patience you must have, my young Padawan*, because optimizing takes time. \n",
    "\n",
    "*Of all the python notebooks in all the towns in all the world, you walk into ours*. How lucky you are, you'll soon see why. \n",
    "\n",
    "So, *say hello to my little friend*, Python's next top model.  \n",
    "Let's *get busy coding, or get busy dying*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import itertools\n",
    "from ipywidgets import Layout\n",
    "import math\n",
    "\n",
    "import time\n",
    "from scipy import linalg\n",
    "import scipy.optimize as optimize\n",
    "import sympy as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_s(keep_top=None):\n",
    "    \"\"\" Prepares data for optimization by creating dummmy-variables for decades, dropping movies with less than 5000 ratings,\n",
    "        dropping some variables that we don't wish to use in the model, and splitting the dataset, so we have a data set\n",
    "        consisting only of the variables used in the model.\n",
    "        \n",
    "    Args:\n",
    "        keep_top (optional, type: int): When a number (n) is put in this option, only the top n movies a kept in the dataset. This is used to sort out movies for a better fit of the model\n",
    "\n",
    "    Returns:\n",
    "        df_X (type: Pandas dataframe): A dataframe consisting only of the varaibles that are used to calculate the rating.\n",
    "        df_Y (type: Pandas dataframe): A dataframe consisting the true rating from the dataset and an index-variable, used for merging with original dataset, later in the process.\n",
    "\n",
    "    Notice:\n",
    "        The function includes global for 'df', which means that the dataframe 'df' generated, can be called outside the function. This is used so that we won't have to filter the original dataframe again, when we use it again.\n",
    "    \"\"\"\n",
    "    global df\n",
    "\n",
    "    # Calls the file 'imdb.csv' which is located in the repository, and contains the dataset used\n",
    "    filename = 'imdb.csv'\n",
    "\n",
    "    # A function generated earlier, which cleans the dataset [Should we include this, and do some of the filtering below in that funciton?]\n",
    "    df = gen_df(filename)\n",
    "\n",
    "    # Generate list of decades for dummies\n",
    "    decade_list = [1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010]\n",
    "\n",
    "    # Decade dummies\n",
    "    for i in decade_list:\n",
    "        df[f'decade_{i}'] = 0\n",
    "        df.loc[(df['decade'] == f'{i}s'),f'decade_{i}'] = 1\n",
    "\n",
    "    # Filters out movies with less than 5000 ratings and drops some genres\n",
    "    df = df.loc[(df['ratingCount']>=5000)]\n",
    "    df = df.drop(columns=['Adult','GameShow','News','RealityTV','TalkShow'])\n",
    "\n",
    "    # Keeps only top n movies, if this is specified when calling the function\n",
    "    if keep_top != None:\n",
    "        df = df.sort_values('imdbRating', ascending=False)\n",
    "        df = df.iloc[:keep_top]\n",
    "\n",
    "    # Splits the dataset into two datasets\n",
    "    df_X = df.copy()\n",
    "    df_Y = pd.DataFrame(df[['imdbRating', 'index']].copy())\n",
    "    df_Y = df_Y.rename(columns = {'imdbRating':'rat_data'})\n",
    "\n",
    "    # Rearrange and keep given columns \n",
    "    df_X = df_X.reindex(['Action','Adventure','Animation','Biography','Comedy','Crime','Documentary',\n",
    "                              'Drama','Family','Fantasy','FilmNoir','History','Horror','Music','Musical',\n",
    "                              'Mystery','Romance','SciFi','Short','Sport','Thriller','War','Western',\n",
    "                              'decade_1920','decade_1930','decade_1940','decade_1950','decade_1960',\n",
    "                              'decade_1970','decade_1980','decade_1990','decade_2000','decade_2010',\n",
    "                              'nrOfNominations','nrOfWins','duration'], axis=1)\n",
    "    \n",
    "    return df_X, df_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for later use \n",
    "variables = ['Action','Adventure','Animation','Biography','Comedy','Crime','Documentary',\n",
    "            'Drama','Family','Fantasy','FilmNoir','History','Horror','Music','Musical',\n",
    "            'Mystery','Romance','SciFi','Short','Sport','Thriller','War','Western',\n",
    "            'decade_1920','decade_1930','decade_1940','decade_1950','decade_1960',\n",
    "            'decade_1970','decade_1980','decade_1990','decade_2000','decade_2010',\n",
    "            'nrOfNominations','nrOfWins','duration']\n",
    "\n",
    "vars_dec = ['Action','Adventure','Animation','Biography','Comedy','Crime','Documentary',\n",
    "        'Drama','Family','Fantasy','FilmNoir','History','Horror','Music','Musical',\n",
    "        'Mystery','Romance','SciFi','Short','Sport','Thriller','War','Western',\n",
    "        'nrOfNominations','nrOfWins','duration']\n",
    "\n",
    "decade_list = [1920, 1930, 1940, 1950, 1960, 1970, 1980, 1990, 2000, 2010]\n",
    "\n",
    "\n",
    "# Function to calculate squared mean differences \n",
    "\n",
    "# OBS: Tilf√∏j evt. andre datadrames and variables (kommentar til Jake)\n",
    "def sqr_diff_sum(df_X,pars):\n",
    "    \"\"\" Generates a float of the sum of squared differences between the ratings from the data and the model. \n",
    "\n",
    "    Args: \n",
    "        df_X (DataFrame): DataFrame containing the variable in x for all observations.\n",
    "        pars (List): List of parameters in omega\n",
    "\n",
    "    Returns: \n",
    "        A float.\n",
    "    \"\"\"\n",
    "    # Calculate the matrix product between omega and X\n",
    "    util = df_X@pars  \n",
    "    # Scale the product so is between 0 and 10. This is the R_model\n",
    "    df_Y['rat_model'] = 10*np.exp(util)/(1+np.exp(util)) \n",
    "    # Calculate the squared difference between R_data and R_model\n",
    "    df_Y['sqr_diff'] = (df_Y['rat_model']-df_Y['rat_data'])**2 \n",
    "\n",
    "    return df_Y['sqr_diff'].sum() # Returns the sum of the squared differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "We analyze preferences for movies by minimizing the sum of the squared differences from our model prediction and the true rating, i.e.:\n",
    "$$\n",
    "\\min_{\\omega} (R_{model}-R_{data})^2\n",
    "$$\n",
    "By doing so, we'll find parameters that best describe movie preferences given our model. As we will discuss later, our model is not necessarily the best model to describe preferences, which might lead to these preferences not being completely true. <br>\n",
    "If the model would predict all movie ratings correctly the parameters would perfectly describe movie preferences. For example if the parameter for action-movies were negative, the prediction would be precise, if action-movies generally had a negative impact on ratings. Of course people have much different preferences, and an interesting analysis would be, to predict preferences for different people, and by this look at a distribution of these parameters. This is not included in this project, though. <br>\n",
    "To shorten the length of the optimizing process, and to sort out movies that makes it harder for the model to predict preferences, the optimization can be based on the top n movies, based on IMDb rating. When all movies are included in the optimizer the lowest ranking movies will have ratings around 2. Our rating predictor will in this case not rank any movies under 5. Thereby it is clear that the predictor model is not able to predict movies with very low rating. But it is able to predict movies with higher rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(keep_top=None, live_graph=True):\n",
    "    \"\"\" Creates and optimizes the function which calculates rating based on variables in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        keep_top (optional, type: int): When a number (n) is put in this option, only the top n movies a kept in the dataset. This is used to sort out movies for a better fit of the model\n",
    "        live_graph(optional, type: boolean): Produces a live graph of the optimization proces, plotting the function values against the iterations. Makes the optimizer slower, but is a good visualization of the process.\n",
    "                                             \n",
    "    Returns:\n",
    "        result (type: scipy optimizer object): An object containing results from the optimizer among other information such as status etc.\n",
    "        timer (type: int): Time of running optimizer in seconds.\n",
    "                                               \n",
    "    Notice:\n",
    "        Uses the package scipy.optimize.minimize which optimizes functions based on a given method. Here 'Nelder-Mead' is used.\n",
    "        This function defines a set of functions used in the optimizer which are not documented by docstring bu comments in code.\n",
    "    \"\"\"\n",
    "    # \"Initializes\" a timer for printing time of optimization\n",
    "    start = time.time()\n",
    "    \n",
    "    # Set of globals so variables can be called inside the functions defined in this function\n",
    "    global fs\n",
    "    global evals\n",
    "    global x0\n",
    "    global df\n",
    "    global df_Y\n",
    "    \n",
    "    # Calculates the sum of the squared differences between rating calculated by model and ratings from the dataset.\n",
    "    # This is what is to be minimized\n",
    "    def sqr_diff_sum(df_X,pars):\n",
    "        global df_Y\n",
    "        util = df_X@pars\n",
    "        df_Y['rat_model'] = 10*np.exp(util)/(1+np.exp(util))\n",
    "        df_Y['sqr_diff'] = (df_Y['rat_model']-df_Y['rat_data'])**2\n",
    "        return df_Y['sqr_diff'].sum()\n",
    "\n",
    "    # List of zeroes for initial guess\n",
    "    def zeros(n): \n",
    "        list = [0] * n\n",
    "        return list \n",
    "    \n",
    "    # Plots a live graph of optimization process, if chosen.\n",
    "    if live_graph:\n",
    "        # The live plot is created by taking the function value for each iteration and saving in a list\n",
    "        def live_plot(evals, fs, ymax=10000, figsize=(7,5)):\n",
    "            # Clears plot every time a new plot is created\n",
    "            clear_output(wait=True)\n",
    "            plt.figure(figsize=figsize)\n",
    "\n",
    "            # Plots values and sets title, grid, labels, etc.\n",
    "            plt.plot(evals, fs)\n",
    "            plt.title('Optimizing path')\n",
    "            plt.grid(True)\n",
    "            plt.xlabel('Iterations')\n",
    "            plt.ylabel('Function value')\n",
    "            plt.xlim(0,20000)\n",
    "            plt.ylim(0,ymax)\n",
    "\n",
    "            plt.show();\n",
    "\n",
    "    # Function to be called by optimizer each iteration. This returns function values for each iteration and plots live graph\n",
    "    def collect(x):\n",
    "        # Set of globals to be called in live graph-function\n",
    "        global fs\n",
    "        global evals\n",
    "        global x0\n",
    "        global fig\n",
    "        global ax\n",
    "        global ymax\n",
    "\n",
    "        # Calculates function value for initial guess, for first iteration\n",
    "        if evals == 0:\n",
    "            fs = []\n",
    "            fs.append(obj_fun(x0))\n",
    "\n",
    "        # Calculates function values for current parameter values\n",
    "        if evals != 0:\n",
    "            fs.append(obj_fun(x))\n",
    "        \n",
    "        # Plots live graph if chosen\n",
    "        if live_graph:\n",
    "            # Calculates max y-value for axis for first iteration\n",
    "            if evals == 1:\n",
    "                ymax = math.ceil(obj_fun(x)/2000)*2000\n",
    "\n",
    "            # Updates plot every 100th iteration for the first 1000 iterations\n",
    "            if evals < 1000:\n",
    "                if evals > 0 and evals%100 == 0:\n",
    "                    live_plot(range(evals+1), fs, ymax)\n",
    "            # Updates plot every 500th iteration for the rest of the process\n",
    "            if evals >=1000:\n",
    "                if evals%500 == 0:\n",
    "                    live_plot(range(evals+1), fs, ymax)\n",
    "        \n",
    "        # Adds one to the number of iterations each iteration\n",
    "        evals += 1\n",
    "    \n",
    "        \n",
    "    # Define datasets to be used using function defined earlier\n",
    "    df_X, df_Y = df_s(keep_top=keep_top)\n",
    "    \n",
    "    # Intiial guess\n",
    "    x0 = zeros(36)\n",
    "    \n",
    "    # Start iteration number\n",
    "    evals = 0\n",
    "    \n",
    "    # Defines function to be minimized\n",
    "    obj_fun = lambda x: sqr_diff_sum(df_X,x)\n",
    "    \n",
    "    # Run optimizer\n",
    "    result = optimize.minimize(obj_fun,x0,\n",
    "                               method=\"Nelder-Mead\",\n",
    "                               options={\"disp\":True, \"maxiter\":50000}, # display the results\n",
    "                               callback=collect\n",
    "                               ) \n",
    "    \n",
    "    # End timer\n",
    "    end = time.time()-start\n",
    "    \n",
    "    # Returns\n",
    "    return result, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run optimizer function and print results and time\n",
    "result, timer = optimizer()\n",
    "print(f'{\" \":9s}Time: {timer:.4f} seconds')\n",
    "\n",
    "# Create a dictionary of parameter results for each variable\n",
    "variables = ['Action','Adventure','Animation','Biography','Comedy','Crime','Documentary',\n",
    "            'Drama','Family','Fantasy','FilmNoir','History','Horror','Music','Musical',\n",
    "            'Mystery','Romance','SciFi','Short','Sport','Thriller','War','Western',\n",
    "            'decade_1920','decade_1930','decade_1940','decade_1950','decade_1960',\n",
    "            'decade_1970','decade_1980','decade_1990','decade_2000','decade_2010',\n",
    "            'nrOfNominations','nrOfWins','duration']\n",
    "\n",
    "results = dict()\n",
    "\n",
    "\n",
    "for j,i in enumerate(variables):\n",
    "    results[i] = result.x[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Idas kode med parameter convergens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OBS: F√∏lgende skal lige tjekkes igennem n√•r SEB har sat kode ind (kommentar til Jake)\n",
    "\n",
    "def optimizer(keep_top=None):\n",
    "    global fs\n",
    "    global evals\n",
    "    global x0\n",
    "    global df\n",
    "    \n",
    "    def sqr_diff_sum(df_X,pars):\n",
    "        util = df_X@pars\n",
    "        df_Y['rat_model'] = 10*np.exp(util)/(1+np.exp(util))\n",
    "        df_Y['sqr_diff'] = (df_Y['rat_model']-df_Y['rat_data'])**2\n",
    "        return df_Y['sqr_diff'].sum()\n",
    "\n",
    "    # Scipy minimize\n",
    "    def zeros(n): \n",
    "        list = [0] * n\n",
    "        return list \n",
    "\n",
    "    df_X, df_Y = df_s(keep_top)\n",
    "    x0 = zeros(len(variables))\n",
    "    evals = 0\n",
    "    \n",
    "    obj_fun = lambda x: sqr_diff_sum(df_X,x)\n",
    "        \n",
    "    result = optimize.minimize(obj_fun,x0,\n",
    "                               method=\"Nelder-Mead\",\n",
    "                               options={\"disp\":True, \"maxiter\":50000}, # display the results\n",
    "                               ) \n",
    "\n",
    "    \n",
    "    return result\n",
    "\n",
    "results = [result.x] # Empty list to store results ######## OBS! ##########\n",
    "\n",
    "# This loop solve the model for the top 500, 1000, and 2000 movies\n",
    "for i in [500, 1000, 2000]:\n",
    "    res_temp = optimizer(keep_top=i)\n",
    "    temp = res_temp.x\n",
    "    results.append(temp) # Store the results in the 'results-list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770d18bc9cd74c81996852302e891c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Nr. of movies', options=('All', 500, 1000, 2000), value='All'), Ou‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## The code creates an interactive plot of the estimated parameters for all variables. \n",
    "## In the interactive part you can choose between estimates when the model is solved \n",
    "## for all movies or just top top 500, 1000, or 2000 rated movies. \n",
    "\n",
    "def fig_2(val):\n",
    "    \"\"\" Generates a figure which plots estimated parameters for all variables.\n",
    "\n",
    "    Args: \n",
    "        val (string or int): Should be one of the elements in the options-list\n",
    "\n",
    "    Returns: \n",
    "        One interactive plot.  \n",
    "\n",
    "    Notice: \n",
    "        The function is generated so that it can be called using widgets.interact. \n",
    "        Thus, it is not intended to be used on its own. \n",
    "    \"\"\"    \n",
    "    fig = plt.figure(figsize=(12,6))\n",
    "    ax1 = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    # Plots the estimated parameters for the chosen sample of movies\n",
    "    ax1.bar(vars2, results[options.index(val)], label=f'Estimates with {options[options.index(val)]} movies')\n",
    "    \n",
    "    # Scatter plot with the estimated paramters for the entire sample \n",
    "    ax1.scatter(vars2, results[0], marker='D', s=15, zorder=2, label='Estimates with all movies')\n",
    "    \n",
    "    # Legends and labels \n",
    "    ax1.legend(loc=\"lower right\")\n",
    "    ax1.set_ylabel('Parameter estimates')\n",
    "    ax1.set_title(f'Parameter estimates for {options[options.index(val)]} movies')\n",
    "    ax1.set_ylim([-0.7,0.7])\n",
    "    ax1.axhline(y=0,color='black',linewidth=1)\n",
    "    for tick in ax1.get_xticklabels():\n",
    "        tick.set_rotation(90)\n",
    "        \n",
    "options = ['All', 500, 1000, 2000] # Option list\n",
    "\n",
    "# Making the figure interactive so the estimates are shown for the chosen sample size \n",
    "widgets.interact(fig_2,\n",
    "    val = widgets.Dropdown(description='Nr. of movies', value='All', options=options, \n",
    "                ),\n",
    ");   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robustness checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction precision\n",
    "Ideally our model would predict movie ratings perfectly, and thereby our parameters would perfectly describe the general preferences for movies. Whether this is possible, even with an advanced model, is not sure. People have different preferences, and two movies that would seem identical in our dataset, based on genres, duration, time of release, etc. could have very different ratings. Therefore som devitaion in our prediction from the true ratings are expected. <br>\n",
    "The left graphs above plot the mean of deviations based on genres, duration, decades, and true ratings. The right graphs plot the number of movies in the dataset based on the same groups. From these graphs we see a clear correlation between precision and number of movies in the dataset. The more movies of a given genre, duration, etc. the more precise the prediction of movie-ratings in these groups. Take drama-movies as an example. The mean of the deviation is close to zero, and movies of this genre is also quite overrepresentated in the dataset. The complete opposite case is short-movies. But we also see that sci-fi-movies are quite well predicted, even though there aren't relatively many of these movies in the dataset. The same is seen in other different genres. <br>\n",
    "This general image is seen when we group movies on decades, duration, and true rating as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_df(df_org):\n",
    "    \"\"\" Merges the original dataset with the optimal solution from the optimizer, i.e. the last dataset of calculated raitngs.\n",
    "    \n",
    "    Args:\n",
    "        df_org (type: Pandas dataframe): The orignal dataset of movies, containing true ratings.\n",
    "        \n",
    "    Returns:\n",
    "        df_merge (type: Pandas dataframe): Original dataset combined with calculated ratings from optimal parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Merges original dataset with optimal ratings based on model\n",
    "    df_merge = df_org.merge(df_Y, how='right', left_on='index', right_on='index')\n",
    "\n",
    "    # Calculates deviations both in normal and absolute form \n",
    "    df_merge['abs_diff'] = abs(df_merge['rat_model']-df_merge['rat_data'])\n",
    "    df_merge['diff'] = df_merge['rat_model']-df_merge['rat_data']\n",
    "    \n",
    "    return df_merge\n",
    "\n",
    "\n",
    "def _mean_genre(df,group):  \n",
    "    \"\"\" Calculates the mean of deviations from true ratings and ratings based on optimal parameters from optimizer.\n",
    "    \n",
    "    Args:\n",
    "        df (type: Pandas dataframe): Dataframe consisting information on groups and deivations\n",
    "        group (type: string): Defines which group mean of deviations are presented for. Chosen by fixed list in widget.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "        \n",
    "    Notice:\n",
    "        Only to be run through widget.interact()\n",
    "    \"\"\"\n",
    "    # List of values used for each group\n",
    "    genre_list = ['Action','Adventure','Animation','Biography','Comedy','Crime','Documentary',\n",
    "                    'Drama','Family','Fantasy','FilmNoir','History','Horror','Music','Musical',\n",
    "                    'Mystery','Romance','SciFi','Short','Sport','Thriller','War','Western']\n",
    "    \n",
    "    decade_list = ['1920s', '1930s', '1940s', '1950s', '1960s', '1970s', '1980s', '1990s', '2000s', '2010s']\n",
    "    \n",
    "    dur_list = [0, .5, 1, 1.5, 2, 2.5, 3, 3.5]\n",
    "    \n",
    "    rat_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    \n",
    "    mean_dict = dict()\n",
    "    count_dict = dict()\n",
    "    \n",
    "    # Creates dictionaries based on chosen group\n",
    "    if group == 'Genres':\n",
    "        for i in genre_list:\n",
    "            I = df[i] == 1\n",
    "            mean_dict[i] = df.loc[I]['diff'].mean()\n",
    "            count_dict[i] = df.loc[I]['index'].count()    \n",
    "\n",
    "    if group == 'Decades':\n",
    "        for i in decade_list:\n",
    "            I = df['decade'] == i\n",
    "            mean_dict[i] = df.loc[I]['diff'].mean()\n",
    "            count_dict[i] = df.loc[I]['index'].count()\n",
    "\n",
    "    if group == 'Duration':\n",
    "        for j,i in enumerate(dur_list):\n",
    "            if j != len(dur_list)-1:\n",
    "                # Uses values from dict, to find movies between to items in the lists.\n",
    "                I = ((df['duration'] >= dur_list[j]) & (df['duration'] < dur_list[j+1]))\n",
    "                mean_dict[f'{dur_list[j]:2.1f} - {dur_list[j+1]:2.1f}'] = df.loc[I]['diff'].mean()\n",
    "                count_dict[f'{dur_list[j]:2.1f} - {dur_list[j+1]:2.1f}'] = df.loc[I]['index'].count()\n",
    "            else:\n",
    "                I = df['duration'] >= dur_list[j]\n",
    "                mean_dict[f'{dur_list[j]:2.1f} {\"+\":5s}'] = df.loc[I]['diff'].mean()\n",
    "                count_dict[f'{dur_list[j]:2.1f} {\"+\":5s}'] = df.loc[I]['index'].count()\n",
    "\n",
    "    if group == 'True rating':\n",
    "        for j,i in enumerate(rat_list):\n",
    "            if j != len(rat_list)-1:\n",
    "                # Uses values from dict, to find movies between to items in the lists.\n",
    "                I = ((df['rat_data'] >= rat_list[j]) & (df['rat_data'] < rat_list[j+1]))\n",
    "                mean_dict[f'{rat_list[j]:4.1f} - {rat_list[j+1]:3.1f}'] = df.loc[I]['diff'].mean()\n",
    "                count_dict[f'{rat_list[j]:4.1f} - {rat_list[j+1]:3.1f}'] = df.loc[I]['index'].count()\n",
    "            else:\n",
    "                pass\n",
    "                           \n",
    "    # Creates figure to hold two subplots \n",
    "    fig1, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,sharey=True,figsize=(12,5))\n",
    "                           \n",
    "    # Plots means of deviations\n",
    "    ax1.barh(*zip(*mean_dict.items()))\n",
    "    ax1.set_ylabel(group)\n",
    "    ax1.set_xlabel('Model deviation')\n",
    "    ax1.grid(axis='x')\n",
    "                           \n",
    "    # Plots count of movies\n",
    "    ax2.barh(*zip(*count_dict.items()))\n",
    "    ax2.set_xlabel('Number of observations')\n",
    "    ax2.grid(axis='x')\n",
    "    \n",
    "    \n",
    "# Calls merge-function\n",
    "df_merge = merge_df(df) \n",
    "\n",
    "# Runs interactive figure \n",
    "mean_genre = widgets.interact(_mean_genre, \n",
    "                             df = widgets.fixed(df_merge),\n",
    "                             group = widgets.Dropdown(\n",
    "                             options = ['Genres','Decades','Duration', 'True rating'],\n",
    "                             description = 'Group',\n",
    "                             value = 'Genres'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decade_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fcad45bf0326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Call the optimize_dec function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mresult_dec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-fcad45bf0326>\u001b[0m in \u001b[0;36moptimizer_dec\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# Make a loop so the model is estimated for all ten decade\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdecade\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecade_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mdf_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_dec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecade\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Call the function to generate the two dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Starting values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decade_list' is not defined"
     ]
    }
   ],
   "source": [
    "## The following code produces the parameter estimates where the sample is restricted to all the decades,\n",
    "## one at the time. The function return a list which contains a list of the estimates for every decade.\n",
    "\n",
    "## OBS: The code will take about 3-4 minutes to run due to the model is estimated 10 times!!\n",
    "\n",
    "def optimizer_dec():\n",
    "    \"\"\" Generates a list containing 10 list with estimates of the model for every decade. \n",
    "    \n",
    "    Args: \n",
    "        No arguments are needed.\n",
    "        \n",
    "    Returns: \n",
    "        A list.\n",
    "        \n",
    "    Notice: \n",
    "        It will raise an error if the function are given an argument!\n",
    "    \"\"\"\n",
    "    \n",
    "    # Defining a function to calculate the sum of squared differences \n",
    "    # between the ratings from the data and from the model. \n",
    "    def sqr_diff_sum(df_X,pars):\n",
    "        \"\"\" Generates a float of the sum of squared differences between the ratings from the data and the model. \n",
    "\n",
    "        Args: \n",
    "            df_X (DataFrame): DataFrame containing the variable in x for all observations.\n",
    "            pars (List): List of parameters in omega\n",
    "\n",
    "        Returns: \n",
    "            A float.\n",
    "        \"\"\"\n",
    "        \n",
    "        util = df_X@pars  # Calculate the matrix product between omega and X\n",
    "        df_Y['rat_model'] = 10*np.exp(util)/(1+np.exp(util)) # Scale the product so is between 0 and 10. This is the R_model\n",
    "        df_Y['sqr_diff'] = (df_Y['rat_model']-df_Y['rat_data'])**2 # Calculate the squared difference between R_data and R_model\n",
    "        return df_Y['sqr_diff'].sum() # Returns the sum of the squared differences\n",
    "                \n",
    "    result = [] # Emty list to store the estimated parameters\n",
    "    \n",
    "    # Make a loop so the model is estimated for all ten decade\n",
    "    for decade in decade_list:      \n",
    "        df_X, df_Y = df_dec(decade) # Call the function to generate the two dataframes\n",
    "        x0 = np.zeros(len(vars_dec)) # Starting values \n",
    "    \n",
    "        obj_fun = lambda x: sqr_diff_sum(df_X,x) # The objective function -> sum of squared differences\n",
    "        \n",
    "        # Use Scipy optimizer to solve the model\n",
    "        result_i = optimize.minimize(obj_fun,x0,\n",
    "                               method='Nelder-Mead',\n",
    "                               options={\"disp\":True, \"maxiter\":50000}, # display the results\n",
    "                               );\n",
    "        \n",
    "        # Add the result for each deacde to the result-list\n",
    "        result.append(list(result_i.x)) \n",
    "                      \n",
    "    return result # Returns the result-list\n",
    "\n",
    "# Call the optimize_dec function\n",
    "result_dec = optimizer_dec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The following code produces a figure with the estimated parameters for each deacde for a chosen variable \n",
    "\n",
    "\n",
    "result_dec_mod = [] # Empty list to storage \n",
    "\n",
    "# The loop changes the order of the result-list so the \n",
    "# estimates are ordered by the variables and subordered by decade \n",
    "# insted of being ordered by decade and subordered by variables \n",
    "for j,var in enumerate(vars):\n",
    "    temp = []\n",
    "    for i,dec in enumerate(decade_list):\n",
    "        temp.append(result_dec[i][j])\n",
    "    \n",
    "    result_dec_mod.append(temp)    \n",
    "    \n",
    "# Defining a figure to plot the estimates \n",
    "def fig(var):\n",
    "    \"\"\" Generates a figure which plots estimated parameters for each decade for one variable \n",
    "\n",
    "    Args: \n",
    "        var (string): Should be one of the variables in the X-vector\n",
    "\n",
    "    Returns: \n",
    "        One interactive plot.  \n",
    "\n",
    "    Notice: \n",
    "        The function is generated so that it can be called using widgets.interact. \n",
    "        Thus, it is not intended to be used on its own. \n",
    "        \"\"\"\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax1 = fig.add_subplot(1,1,1)\n",
    "    \n",
    "    \n",
    "    ax1.bar(decade_list, result_dec_mod[vars.index(var)],width=6)\n",
    "    \n",
    "    # Setting labels, ticks etc. \n",
    "    ax1.set_ylabel('Parameter estimates')\n",
    "    ax1.set_title(f'Parameter estimates for {var} per decade')\n",
    "    ax1.set_xticks(decade_list)\n",
    "    ax1.axhline(y=0,color='black',linewidth=1)\n",
    "\n",
    "# Making the figure interactive so the estimates are shown for the chosen variable \n",
    "widgets.interact(fig,\n",
    "    var = widgets.Dropdown(description='Variable', value='Action', options=vars, \n",
    "                ),\n",
    ");    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
